{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import STOPWORDS,WordCloud\n",
    "import numpy as np\n",
    "import string, os, re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/transcribed_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adunit-ihop-window4-reeses-mpu</td>\n",
       "      <td>You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>919ef5d6de221daf94537e4d87e98859</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6a8e741867d4f893afad015b77b52c39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ec53b0973db5a35d83fd5bb009802bdb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db671d7ebafdc3b7259109fbc18eaac9</td>\n",
       "      <td>I'm so for you. Far and love. With the highly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            game_id  \\\n",
       "0    adunit-ihop-window4-reeses-mpu   \n",
       "1  919ef5d6de221daf94537e4d87e98859   \n",
       "2  6a8e741867d4f893afad015b77b52c39   \n",
       "3  ec53b0973db5a35d83fd5bb009802bdb   \n",
       "4  db671d7ebafdc3b7259109fbc18eaac9   \n",
       "\n",
       "                                                text  \n",
       "0                                                You  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4   I'm so for you. Far and love. With the highly...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_id      0\n",
       "text       173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(' ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adunit-ihop-window4-reeses-mpu</td>\n",
       "      <td>You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>919ef5d6de221daf94537e4d87e98859</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6a8e741867d4f893afad015b77b52c39</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ec53b0973db5a35d83fd5bb009802bdb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db671d7ebafdc3b7259109fbc18eaac9</td>\n",
       "      <td>I'm so for you. Far and love. With the highly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            game_id  \\\n",
       "0    adunit-ihop-window4-reeses-mpu   \n",
       "1  919ef5d6de221daf94537e4d87e98859   \n",
       "2  6a8e741867d4f893afad015b77b52c39   \n",
       "3  ec53b0973db5a35d83fd5bb009802bdb   \n",
       "4  db671d7ebafdc3b7259109fbc18eaac9   \n",
       "\n",
       "                                                text  \n",
       "0                                                You  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4   I'm so for you. Far and love. With the highly...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_first(text):\n",
    "    # Remove the stop words to prepare the word clouds\n",
    "    stopWords = set(STOPWORDS)\n",
    "    # stopWords.update([\"RT\",\"https\",\"will\",\"the\"])\n",
    "    \n",
    "    # Regex patterns\n",
    "    urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    userPattern       = '@[^\\s]+'\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "    \n",
    "\n",
    "    # remove stop words\n",
    "    text = text.apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stopWords))    \n",
    "    # remove @username \n",
    "    text = text.apply(lambda words: ' '.join(re.sub(urlPattern,' ',word) for word in words.split() ))\n",
    "    # remove all urls \n",
    "    text = text.apply(lambda words: ' '.join(re.sub(userPattern,' ', word) for word in words.split() ))\n",
    "    # Replace 3 or more consecutive letters by 2 letter.\n",
    "    text = text.str.replace('[^a-zA-Z\\s]', ' ')\n",
    "    #     /^[a-zA-Z\\s]*$/g\n",
    "    text = text.apply(lambda words: ' '.join(re.sub(sequencePattern, seqReplacePattern, word) for word in words.split() ))\n",
    "    # remove characters and non-english letters\n",
    "    \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owon/anaconda3/envs/newenv/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "clean_text =  preprocess_first(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                    you\n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4      i m you far love with highly awarded alcerdifi...\n",
       "                             ...                        \n",
       "508                                                  you\n",
       "509                                                     \n",
       "510                                                     \n",
       "511                                                  you\n",
       "512                                                     \n",
       "Name: text, Length: 513, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Functions for data cleaning\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize(myWord):\n",
    "    \"\"\"Function to lemmatize words\"\"\"\n",
    "    if myWord is None:\n",
    "        return myWord\n",
    "    else:\n",
    "        return str(wnl.lemmatize(myWord))\n",
    "\n",
    "\n",
    "def prepText(myWord):\n",
    "    \"\"\"Final text pre-processing function\"\"\"\n",
    "    return lemmatize(\n",
    "                myWord.lower()\n",
    "        )\n",
    "    \n",
    "def filterTextList(textList):\n",
    "    \"\"\" lemmatize, and clean all tweets\"\"\"\n",
    "    return [[prepText(word) for word\n",
    "                in text.split()\n",
    "                    if prepText(word) is not None]\n",
    "                for text in textList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the cleaning function\n",
    "stopWords = set(STOPWORDS)\n",
    "clean_textList = filterTextList(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting texts to list of words For feature engineering\n",
    "sentence_list = [text_each for text_each in text]\n",
    "word_list = [sent.split() for sent in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plain Sentence:  Can't take my eyes off of you. Far and love. With the highly awarded, El certified by Lex's collection of pre-em vehicles. Exclusively are your Lex's dealer.\n",
      "\n",
      "Generated List: \n",
      "[\"Can't\", 'take', 'my', 'eyes', 'off', 'of', 'you.', 'Far', 'and', 'love.', 'With', 'the', 'highly', 'awarded,', 'El', 'certified', 'by', \"Lex's\", 'collection', 'of', 'pre-em', 'vehicles.', 'Exclusively', 'are', 'your', \"Lex's\", 'dealer.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# showing the list of words\n",
    "print('\\nPlain Sentence: ' + text.values[12] + '\\n')\n",
    "print('Generated List: \\n'+ str(word_list[12]))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_category(p):\n",
    "    v = TextBlob(p).sentiment.polarity\n",
    "    if v > 0:\n",
    "        return 'positive'\n",
    "    elif v < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/owon/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import operator\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df[\"sentiment_score\"] = df[\"clean_text\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n",
    "df[\"sentiment\"] = np.select([df[\"sentiment_score\"] < 0, df[\"sentiment_score\"] == 0, df[\"sentiment_score\"] > 0],\n",
    "                           ['negative', 'neutral', 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       neutral\n",
       "1       neutral\n",
       "2       neutral\n",
       "3       neutral\n",
       "4      positive\n",
       "         ...   \n",
       "508     neutral\n",
       "509     neutral\n",
       "510     neutral\n",
       "511     neutral\n",
       "512     neutral\n",
       "Name: sentiment, Length: 513, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['clean_text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     334\n",
       "positive    152\n",
       "negative     27\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['game_id', 'sentiment_score','sentiment','word_count']].to_csv('../data/sentiment.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('newenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5c95f6d498df283b42a04cb760829a6e6ab9154c751492a5bf0cfc55ea1de82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
